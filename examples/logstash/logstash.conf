# Logstash configuration for log redaction
# https://www.elastic.co/guide/en/logstash/current/index.html

input {
  # Read from files
  file {
    path => "/var/log/app/*.log"
    start_position => "beginning"
    tags => ["app", "security"]
    codec => json
  }
  
  file {
    path => "/var/log/nginx/access.log"
    start_position => "beginning"
    tags => ["nginx", "access"]
  }
  
  # Read from beats
  beats {
    port => 5044
    tags => ["beats"]
  }
  
  # Read from syslog
  syslog {
    port => 514
    tags => ["syslog"]
  }
  
  # Read from Kafka
  kafka {
    bootstrap_servers => "kafka.local:9092"
    topics => ["raw-security-logs"]
    codec => json
    consumer_threads => 4
    tags => ["kafka"]
  }
}

filter {
  # Parse nginx logs
  if "nginx" in [tags] {
    grok {
      match => { "message" => "%{NGINXACCESS}" }
    }
    
    date {
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
    }
  }
  
  # Parse JSON messages
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
    }
  }
  
  # Apply redaction using external script
  ruby {
    code => '
      require "open3"
      require "json"
      
      begin
        # Get the event as JSON
        event_json = event.to_hash.to_json
        
        # Run redaction script
        cmd = "python3 /opt/redact.py --rules /opt/redaction-rules.yaml"
        stdout, stderr, status = Open3.capture3(cmd, stdin_data: event_json)
        
        if status.success?
          # Parse redacted result
          redacted_data = JSON.parse(stdout.strip)
          
          # Update event with redacted data
          redacted_data.each do |key, value|
            event.set(key, value)
          end
          
          # Add redaction metadata
          event.set("[@metadata][redacted]", true)
          event.set("[@metadata][redacted_timestamp]", Time.now.iso8601)
          event.set("[@metadata][redacted_by]", "logstash-redactor")
        else
          event.set("[@metadata][redaction_error]", stderr)
          logger.warn("Redaction failed", :error => stderr)
        end
      rescue => e
        event.set("[@metadata][redaction_exception]", e.message)
        logger.error("Redaction exception", :exception => e)
      end
    '
  }
  
  # Alternative: Manual redaction rules in Logstash
  if [@metadata][redaction_error] {
    # Fallback redaction using Logstash filters
    
    # Remove sensitive fields
    mutate {
      remove_field => ["password", "passwd", "secret", "token", "api_key"]
    }
    
    # Redact IP addresses
    if [client_ip] {
      ruby {
        code => '
          ip = event.get("client_ip")
          if ip && ip.match(/^\d+\.\d+\.\d+\.\d+$/)
            parts = ip.split(".")
            redacted_ip = "#{parts[0]}.#{parts[1]}.#{parts[2]}.xxx"
            event.set("client_ip", redacted_ip)
          end
        '
      }
    }
    
    # Redact email addresses
    mutate {
      gsub => [
        "message", "([a-zA-Z0-9._%+-]+)@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}", "\1@***"
      ]
    }
    
    # Redact phone numbers (Chinese format)
    mutate {
      gsub => [
        "message", "\b(1[3-9]\d)\d{4}(\d{4})\b", "\1****\2"
      ]
    }
  }
  
  # Add processing metadata
  mutate {
    add_field => {
      "[@metadata][processed_timestamp]" => "%{+yyyy-MM-dd HH:mm:ss}"
      "[@metadata][processor]" => "logstash"
    }
  }
  
  # Normalize timestamps
  date {
    match => [ "timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss" ]
    target => "@timestamp"
  }
  
  # Add GeoIP for non-redacted IPs (for analytics)
  if [client_ip] and ![@metadata][redacted] {
    geoip {
      source => "client_ip"
      target => "geoip"
      add_tag => ["geoip"]
    }
  }
}

output {
  # Output to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch.local:9200"]
    index => "security-logs-redacted-%{+yyyy.MM.dd}"
    template_name => "security-logs"
    template_pattern => "security-logs-*"
    template => "/etc/logstash/templates/security-logs.json"
    
    # Authentication
    user => "elastic"
    password => "${ELASTIC_PASSWORD}"
    
    # Performance tuning
    workers => 4
    flush_size => 500
    idle_flush_time => 5
  }
  
  # Output to file (backup)
  file {
    path => "/var/log/redacted/security-%{+yyyy-MM-dd}.log"
    codec => json_lines
  }
  
  # Output to Kafka (for further processing)
  kafka {
    bootstrap_servers => "kafka.local:9092"
    topic_id => "security-logs-redacted"
    codec => json
    compression_type => "gzip"
    batch_size => 100
  }
  
  # Conditional outputs based on log type
  if "nginx" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch.local:9200"]
      index => "nginx-logs-redacted-%{+yyyy.MM.dd}"
    }
  }
  
  if "app" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch.local:9200"]
      index => "app-logs-redacted-%{+yyyy.MM.dd}"
    }
  }
  
  # Debug output (remove in production)
  if [@metadata][redaction_error] {
    stdout {
      codec => rubydebug
    }
  }
}